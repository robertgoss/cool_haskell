{
module Main (main) where

import Token(Token(..),display)
import StringTab

import System.Environment
import System.IO



}

%wrapper "gscan"

@darrow        =  \=\>

tokens :-


--  Put your rules here

  --Multichar operations
<0>@darrow                           { tok DARROW }

{

--Do not change the main function definiton else your program may not submit properly
main = do
  args <- getArgs
  filename <- return (head args)
  putStrLn ("#name " ++ show filename)
  h <- openFile filename ReadMode
  s <- hGetContents h
  sequence $ map (putStrLn.show') (alexGScan stop initialState s)
  where
    show' :: TokenLine -> String
    show' (l,ts,s) = "#" ++ (show l) ++ " " ++ (display ts s)


-- Some action helpers:

-- The state we want to carry around as we lex
--     You may need to alter this!
--     For now just an integer representing the current line number
--         some tables representing the current string tables and
--         a string which you (may) use to buffer a string.
type LexState = (Int,Tables,String)

--Sets the initial state of the parser
initialState :: LexState
initialState = (1,initTables,"")

--Get the current string tables
tables :: LexState -> Tables
tables (_,ts,_) = ts

--Get the current line number from the lex state
line_number :: LexState -> Int
line_number (l,_,_) = l

add_line :: LexState -> LexState
add_line (l,t,s) = (l+1,t,s)


-- A triple of line number tables at a point in the lex and a token
-- this is all the information you return about a token and it's context
type TokenLine = (Int,Tables,Token)

--Type of token action in the gscan wrapper
type TokenAction =  AlexPosn                            -- Alex internal position in 
                                                        --   lexing not used here
                    -> Char                             -- 1 char of lookahead
                    -> String                           -- The rest of the string not yet tokenized
                    -> Int                              -- The length of matched text.
                    -> ((Int,LexState)->[TokenLine])  -- A continuation function
                                                        -- What to do after this token is lexed.
                    -> (Int,LexState)                 -- The internal alex state number and 
                                                        --   the users lex state
                    -> [TokenLine]                      -- The resulting list of tokens

--Helper function to create token action from a token constructors

toks :: (String -> Token) -> TokenAction          
toks f _ _ str len cont (sc,state) = (line, ts, f match) : cont (sc,state)
  where line = line_number state
        match = take len str
        ts = tables state

--Helper function to create token action from a given token

tok :: Token -> TokenAction
tok t = toks (\s -> t)

-- A trivial token ation which ignores this token

ignore :: TokenAction
ignore _ _ _ _ cont (s,ps) = cont (s,ps)


-- Add a new line when doing a token action
newline :: TokenAction -> TokenAction
newline act p c s i cont (sc,ls) = act p c s i cont (sc,newls)
  where newls = add_line ls


--The stop function called when the lexer reaches an EOF
--You may need to alter this
stop :: AlexPosn    -- Internal alex position at EOF do not use 
	-> Char           -- lookahead char do not use
	-> String         -- any text still unmatched when EOF reached
	-> (Int,LexState) -- Alex state number and user state of lexer 
                    --  when EOF reached.
	-> [TokenLine]    -- List of tokens to return.
stop _ _ "" (0,s) = []      -- No error at end of lexing.


}
